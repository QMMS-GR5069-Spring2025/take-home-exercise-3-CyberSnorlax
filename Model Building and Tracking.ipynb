{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0499f928-1b76-44be-b047-0a8f0cff1284",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.spark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c7c3147c-3dee-41c4-9400-85ba1bf6131a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "races = spark.read.csv(\"s3://columbia-gr5069-main/raw/races.csv\", header=True, inferSchema=True)\n",
    "results = spark.read.csv(\"s3://columbia-gr5069-main/raw/results.csv\", header=True, inferSchema=True)\n",
    "drivers = spark.read.csv(\"s3://columbia-gr5069-main/raw/drivers.csv\", header=True, inferSchema=True)\n",
    "circuits = spark.read.csv(\"s3://columbia-gr5069-main/raw/circuits.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ddc80bdf-d9e6-4d97-9f44-01f523e0360d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def prepare_data():\n",
    "    # Join datasets\n",
    "    data = results.join(races, \"raceId\") \\\n",
    "                 .join(drivers, \"driverId\") \\\n",
    "                 .join(circuits, \"circuitId\") \\\n",
    "                 .select(\n",
    "                     \"positionOrder\",  # Target variable\n",
    "                     \"grid\",\n",
    "                     \"laps\",\n",
    "                     \"points\",\n",
    "                     \"year\",\n",
    "                     \"round\",\n",
    "                     \"circuitId\",\n",
    "                     \"driverId\"\n",
    "                 )\n",
    "    \n",
    "    # Handle missing values and create features\n",
    "    data = data.na.fill(0)\n",
    "    \n",
    "    # Create feature vector\n",
    "    feature_cols = [\"grid\", \"laps\", \"points\", \"year\", \"round\", \"circuitId\", \"driverId\"]\n",
    "    assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
    "    final_data = assembler.transform(data)\n",
    "    \n",
    "    return final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "72683d00-20ab-475d-af97-7bb9ba3e1c62",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "prepare_data().display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b3e3b5a7-d12e-4fa4-9958-46cb5ad0ee2e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "feature_cols = [\"grid\", \"laps\", \"points\", \"year\", \"round\", \"circuitId\", \"driverId\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ba18f96-5f87-4a66-a3cd-26df9efcce2d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def create_plots(y_true, y_pred, run_id, feature_importances):\n",
    "    # Confusion Matrix\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    cm = pd.crosstab(y_true, y_pred)  # y_true and y_pred are 1D Series\n",
    "    cm.plot(kind='bar')\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.savefig(f\"/dbfs/confusion_matrix_{run_id}.png\")\n",
    "    plt.close()  \n",
    "    # Feature Importance\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(range(len(feature_cols)), feature_importances)\n",
    "    plt.xticks(range(len(feature_cols)), feature_cols, rotation=45)\n",
    "    plt.title(\"Feature Importance\")\n",
    "    plt.savefig(f\"/dbfs/feature_importance_{run_id}.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b42b46b8-b4e4-4fb2-9966-e921aa3e5e8d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mlflow.set_experiment(\"/Users/yw4407@columbia.edu/F1_Race_Prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c93a728a-63b3-4507-bc0a-4fedd7fde014",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data = prepare_data()\n",
    "train_data, test_data = data.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "73f5fe33-9973-4aad-bc1c-3c71f1910baf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {\"numTrees\": nt, \"maxDepth\": md}\n",
    "    for nt in [10, 20, 30, 40, 50]\n",
    "    for md in [5, 10]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d9a306c9-ed23-4e4e-9007-daf59804f178",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "for params in param_grid[:10]:  # Ensure exactly 10 runs\n",
    "    with mlflow.start_run():\n",
    "        # Create and train model\n",
    "        rf = RandomForestClassifier(\n",
    "            labelCol=\"positionOrder\",\n",
    "            featuresCol=\"features\",\n",
    "            numTrees=params[\"numTrees\"],\n",
    "            maxDepth=params[\"maxDepth\"]\n",
    "        )\n",
    "        model = rf.fit(train_data)\n",
    "        \n",
    "        # Make predictions\n",
    "        predictions = model.transform(test_data)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        evaluators = {\n",
    "            \"accuracy\": MulticlassClassificationEvaluator(labelCol=\"positionOrder\", predictionCol=\"prediction\", metricName=\"accuracy\"),\n",
    "            \"f1\": MulticlassClassificationEvaluator(labelCol=\"positionOrder\", predictionCol=\"prediction\", metricName=\"f1\"),\n",
    "            \"weightedPrecision\": MulticlassClassificationEvaluator(labelCol=\"positionOrder\", predictionCol=\"prediction\", metricName=\"weightedPrecision\"),\n",
    "            \"weightedRecall\": MulticlassClassificationEvaluator(labelCol=\"positionOrder\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
    "        }\n",
    "        \n",
    "        # Log parameters\n",
    "        mlflow.log_params(params)\n",
    "        \n",
    "        # Log metrics\n",
    "        metrics = {metric: evaluator.evaluate(predictions) for metric, evaluator in evaluators.items()}\n",
    "        mlflow.log_metrics(metrics)\n",
    "        \n",
    "        # Log model with explicit pip requirements to avoid warning\n",
    "        mlflow.spark.log_model(model, \"model\", pip_requirements=[\"pyspark==3.5.0\"])\n",
    "        \n",
    "        # Create and log artifacts\n",
    "        run_id = mlflow.active_run().info.run_id\n",
    "        y_true = predictions.select(\"positionOrder\").toPandas()[\"positionOrder\"]  # Extract Series\n",
    "        y_pred = predictions.select(\"prediction\").toPandas()[\"prediction\"]  # Extract Series\n",
    "        \n",
    "        create_plots(y_true, y_pred, run_id, model.featureImportances.toArray())\n",
    "        \n",
    "        # Save predictions as CSV\n",
    "        predictions.select(\"positionOrder\", \"prediction\", \"features\") \\\n",
    "                  .toPandas() \\\n",
    "                  .to_csv(f\"/dbfs/predictions_{run_id}.csv\")\n",
    "        \n",
    "        # Log artifacts\n",
    "        mlflow.log_artifact(f\"/dbfs/confusion_matrix_{run_id}.png\")\n",
    "        mlflow.log_artifact(f\"/dbfs/feature_importance_{run_id}.png\")\n",
    "        mlflow.log_artifact(f\"/dbfs/predictions_{run_id}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b2a93949-13dd-46f2-b046-e9150631ed7f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Model selection and explanation\n",
    "runs = mlflow.search_runs()\n",
    "best_run = runs.loc[runs['metrics.accuracy'].idxmax()]\n",
    "print(f\"Best model Run Name: {best_run['tags.mlflow.runName']}\")\n",
    "print(f\"Best model Run ID: {best_run['run_id']}\")\n",
    "print(f\"Parameters: numTrees={best_run['params.numTrees']}, maxDepth={best_run['params.maxDepth']}\")\n",
    "print(f\"Metrics: {best_run.filter(like='metrics').to_dict()}\")\n",
    "print(\"\"\"\n",
    "Explanation: The best model was selected based on highest accuracy score as it provides\n",
    "the most reliable predictions for race position outcomes. This model balances complexity\n",
    "(numTrees and maxDepth) with performance, avoiding overfitting while capturing key\n",
    "patterns in the F1 race data.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c3097f3-c2cd-4571-a82f-d53604b9c9c1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Model Building and Tracking",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
